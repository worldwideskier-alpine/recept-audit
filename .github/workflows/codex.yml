name: "Codex"

on:
  workflow_dispatch:
  push:
    paths:
      - "spec/**"
      - ".github/workflows/codex.yml"

permissions:
  contents: write
  pull-requests: write

jobs:
  generate:
    runs-on: "ubuntu-24.04"
    env:
      OPENAI_API_KEY: "${{ secrets.OPENAI_API_KEY }}"
      OPENAI_MODEL: "gpt-5-codex"
      ENDPOINT: "https://api.openai.com/v1/chat/completions"
      SPEC_ROOT: "spec"
      SPEC_DIRS: "env foundation features tests"
      PROMPT_FILE: "ai/prompt.md"
      REQUEST_JSON: "ai/request.json"
      RESPONSE_JSON: "ai/response.json"
      OUT_JSON: "ai/out.files.json"
      MAX_TOKENS: "12288"
      CURL_TIMEOUT: "300"
      CURL_RETRIES: "5"
      CURL_RETRY_DELAY: "5"

    steps:
      - name: "Checkout"
        uses: "actions/checkout@v4"
        with:
          fetch-depth: 1

      - name: "Install jq and coreutils"
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq coreutils

      - name: "Build prompt"
        shell: "bash"
        run: |
          set -euo pipefail
          mkdir -p "ai"
          : > "$PROMPT_FILE"
          {
            printf "# Codex generation prompt\n\n"
            printf "## STRICT RULES\n\n"
            printf -- "- Return ONLY JSON (no prose) that matches {\"files\":[{\"path\":string,\"content\":string},...]}.\n"
            printf -- "- Implement runnable APPLICATION CODE and TESTS.\n"
            printf -- "- Emit at least one code file under \"/src\" or \"/app\".\n"
            printf -- "- You may also emit build files: \"package.json\", \"tsconfig.json\", \"pyproject.toml\", \"requirements.txt\", \"composer.json\", \"go.mod\".\n"
            printf -- "- Do NOT create policy/compliance/README/meta docs.\n"
            printf -- "- NEVER write under the \"ai/\" directory.\n\n"
            printf "## SPEC CONTENT\n"
          } >> "$PROMPT_FILE"

          tmp_list="$(mktemp)"
          for d in $SPEC_DIRS; do
            [ -d "${SPEC_ROOT}/${d}" ] || continue
            find "${SPEC_ROOT}/${d}" -type f \( -name "*.md" -o -name "*.txt" -o -name "*.yaml" -o -name "*.yml" -o -name "*.json" \) >> "$tmp_list"
          done
          LC_ALL=C sort -o "$tmp_list" "$tmp_list" || true
          while IFS= read -r f; do
            printf "\n### %s\n\n" "$f" >> "$PROMPT_FILE"
            sed -e "s/\r$//" "$f" | head -n 4000 >> "$PROMPT_FILE"
          done < "$tmp_list"
          rm -f "$tmp_list"

      - name: "Create branch"
        shell: "bash"
        run: |
          set -euo pipefail
          BRANCH_NAME="codex/autogen-${GITHUB_RUN_ID}"
          echo "BRANCH_NAME=${BRANCH_NAME}" >> "$GITHUB_ENV"
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git checkout -b "${BRANCH_NAME}"

      - name: "Call OpenAI (Chat Completions, JSON-only)"
        shell: "bash"
        env:
          AUTH_HEADER: "Authorization: Bearer ${{ secrets.OPENAI_API_KEY }}"
        run: |
          set -euo pipefail

          jq -n \
            --arg model "$OPENAI_MODEL" \
            --rawfile prompt "$PROMPT_FILE" \
            --argjson max_tokens "${MAX_TOKENS}" \
            '{
               "model": $model,
               "temperature": 0,
               "response_format": {"type":"json_object"},
               "messages": [
                 {"role":"system","content":"You are Codex. Output ONLY a JSON object with the exact shape {\"files\":[{\"path\":string,\"content\":string},...]}. No prose, no code fences. Write full, runnable code. No placeholders. Never write inside ai/."},
                 {"role":"user","content": ("Implement the SPEC as runnable application code and tests. Return files to write as JSON only.\n\n" + $prompt)}
               ]
             }
             | if ($max_tokens // 0) > 0 then . + {"max_tokens": $max_tokens} else . end' > "$REQUEST_JSON"

          status="$(curl -sS --connect-timeout 30 --max-time "${CURL_TIMEOUT}" \
            --retry "${CURL_RETRIES}" --retry-all-errors --retry-delay "${CURL_RETRY_DELAY}" \
            -H "$AUTH_HEADER" \
            -H "Content-Type: application/json" \
            -w "\n%{http_code}\n" \
            -d @"$REQUEST_JSON" "$ENDPOINT" | tee "$RESPONSE_JSON" | tail -n1)"

          head -n -1 "$RESPONSE_JSON" > "${RESPONSE_JSON}.tmp" && mv -f "${RESPONSE_JSON}.tmp" "$RESPONSE_JSON"

          echo "OpenAI HTTP status: ${status}"
          [ "${status}" -ge 200 ] && [ "${status}" -lt 300 ]

          jq -e -r '.choices[0].message.content' "$RESPONSE_JSON" | jq -e '.' > "$OUT_JSON"

          jq -r '.files[] | @base64' "$OUT_JSON" | while read -r row; do
            _jq(){ echo "$row" | base64 -d | jq -r "$1"; }
            path="$(_jq ".path")"
            content="$(_jq ".content")"
            case "$path" in
              ai/*) echo "::warning::skip ai/: ${path}"; continue ;;
            esac
            mkdir -p "$(dirname "$path")"
            printf "%s" "$content" > "$path"
            git add "$path"
          done

          if ! git diff --cached --name-only | grep -q "."; then
            echo "::error::No files were emitted by the model."
            exit 6
          fi

          git commit -m "codex(init): seed via ${OPENAI_MODEL}"
          git push -u origin "${BRANCH_NAME}"

      - name: "Upload debug artifacts"
        if: "always()"
        uses: "actions/upload-artifact@v4"
        with:
          name: "ai-debug"
          path: |
            ai/prompt.md
            ai/request.json
            ai/response.json
            ai/out.files.json
          if-no-files-found: "warn"
