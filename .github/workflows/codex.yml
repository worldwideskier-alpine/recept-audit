name: Codex

on:
  workflow_dispatch:

permissions:
  contents: write
  pull-requests: write

jobs:
  generate:
    runs-on: ubuntu-24.04

    env:
      OPENAI_MODEL: gpt-5-codex
      ENDPOINT: https://api.openai.com/v1/responses
      SPEC_ROOT: spec
      SPEC_DIRS: env foundation features tests
      PROMPT_FILE: ai/prompt.md
      REQUEST_JSON: ai/request.json
      RESPONSE_JSON: ai/response.json
      OUT_JSON: ai/out.files.json
      # 出力トークン上限。安全値から開始（必要に応じて上げる）
      MAX_TOKENS: 4096
      CURL_TIMEOUT: 300
      CURL_RETRIES: 5
      CURL_RETRY_DELAY: 5

    steps:
      - uses: actions/checkout@v4
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

      - name: Install jq
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq coreutils

      - name: Build prompt from SPEC
        run: |
          set -euo pipefail
          mkdir -p ai
          : > "$PROMPT_FILE"
          {
            printf "# Codex generation prompt\n\n"
            printf "## STRICT RULES\n\n"
            printf -- "- Return ONLY JSON (no prose) that matches {\"files\":[{\"path\":string,\"content\":string},...]}.\n"
            printf -- "- Implement runnable APPLICATION CODE and TESTS.\n"
            printf -- "- Emit at least one code file under \"/src\" or \"/app\".\n"
            printf -- "- You may also emit build files: \"package.json\", \"tsconfig.json\", \"pyproject.toml\", \"requirements.txt\", \"composer.json\", \"go.mod\".\n"
            printf -- "- Do NOT create policy/compliance/README/meta docs.\n"
            printf -- "- NEVER write under the \"ai/\" directory.\n\n"
            printf "## SPEC CONTENT\n"
          } >> "$PROMPT_FILE"

          tmp_list="$(mktemp)"
          for d in $SPEC_DIRS; do
            [ -d "${SPEC_ROOT}/${d}" ] || continue
            find "${SPEC_ROOT}/${d}" -type f \( -name "*.md" -o -name "*.txt" -o -name "*.yaml" -o -name "*.yml" -o -name "*.json" \) >> "$tmp_list"
          done
          LC_ALL=C sort -o "$tmp_list" "$tmp_list" || true
          while IFS= read -r f; do
            printf "\n### %s\n\n" "$f" >> "$PROMPT_FILE"
            # 各ファイルの先頭 4000 行までを取り込み（過剰な入力での 400 を回避）
            sed -e 's/\r$//' "$f" | head -n 4000 >> "$PROMPT_FILE"
          done < "$tmp_list"
          rm -f "$tmp_list"

      - name: Create working branch
        run: |
          set -euo pipefail
          BRANCH_NAME="codex/autogen-${GITHUB_RUN_ID}"
          echo "BRANCH_NAME=${BRANCH_NAME}" >> "$GITHUB_ENV"
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git checkout -b "${BRANCH_NAME}"

      - name: Call OpenAI (Responses API, strict JSON schema)
        env:
          AUTH_HEADER: Authorization: Bearer ${{ secrets.OPENAI_API_KEY }}
        run: |
          set -euo pipefail

          # Build request body (typed content + strict JSON Schema)
          jq -n \
            --arg model "$OPENAI_MODEL" \
            --rawfile prompt "$PROMPT_FILE" \
            --argjson max_out "${MAX_TOKENS:-0}" \
            '{
              model: $model,
              temperature: 0,
              modalities: ["text"],
              response_format: {
                type: "json_schema",
                json_schema: {
                  name: "emit_files",
                  schema: {
                    type: "object",
                    additionalProperties: false,
                    required: ["files"],
                    properties: {
                      files: {
                        type: "array",
                        minItems: 1,
                        items: {
                          type: "object",
                          additionalProperties: false,
                          required: ["path","content"],
                          properties: {
                            path:    { type: "string", minLength: 1 },
                            content: { type: "string" }
                          }
                        }
                      }
                    }
                  },
                  strict: true
                }
              },
              input: [
                {
                  role: "system",
                  content: [
                    { "type":"input_text",
                      "text":"You are Codex. Output ONLY a JSON object with the exact shape {\\\"files\\\":[{\\\"path\\\":string,\\\"content\\\":string},...]}. No prose, no code fences. Write full, runnable code. No placeholders. Never write inside ai/."
                    }
                  ]
                },
                {
                  role: "user",
                  content: [
                    { "type":"input_text",
                      "text": ("Implement the SPEC as runnable application code and tests. Return files to write as JSON only.\n\n" + $prompt)
                    }
                  ]
                }
              ]
            }
            | if $max_out > 0 then . + {max_output_tokens: $max_out} else . end' > "$REQUEST_JSON"

          # Call API (必ずボディを保存し、HTTP ステータスで分岐)
          status="$(curl -sS --connect-timeout 30 --max-time "${CURL_TIMEOUT}" \
            --retry "${CURL_RETRIES}" --retry-all-errors --retry-delay "${CURL_RETRY_DELAY}" \
            -H "$AUTH_HEADER" \
            -H "Content-Type: application/json" \
            -w "\n%{http_code}\n" \
            -d @"$REQUEST_JSON" "$ENDPOINT" \
            | tee "$RESPONSE_JSON" | tail -n1)"

          # tee が付けた末尾の HTTP コード行を除去
          head -n -1 "$RESPONSE_JSON" > "${RESPONSE_JSON}.tmp" && mv -f "${RESPONSE_JSON}.tmp" "$RESPONSE_JSON"

          echo "OpenAI HTTP status: ${status}"

          # 200 台以外は error.message を表示して fail
          if [ "$status" -lt 200 ] || [ "$status" -ge 300 ]; then
            msg="$(jq -r '.error.message // .message // "Unknown error"' "$RESPONSE_JSON")"
            echo "::error title=OpenAI API error::${msg}"
            exit 1
          fi

          # Responses API のどの形でも拾える抽出パス
          jq -e -r '
            (.output[]?.content[]? | select(.type=="output_text") | .text)
            // (.output_text)
            // (.response)
          ' "$RESPONSE_JSON" | jq -e '.' > "$OUT_JSON"

      - name: Write emitted files & push branch
        run: |
          set -euo pipefail
          jq -r '.files[] | @base64' "$OUT_JSON" | while read -r row; do
            _jq(){ echo "$row" | base64 -d | jq -r "$1"; }
            path="$(_jq ".path")"
            content="$(_jq ".content")"

            case "$path" in
              ai/*) echo "::warning::skip ai/: ${path}"; continue ;;
            esac

            mkdir -p "$(dirname "$path")"
            printf "%s" "$content" > "$path"
            git add "$path"
          done

          if ! git diff --cached --name-only | grep -q .; then
            echo "::error::No files were emitted by the model."
            exit 6
          fi

          git commit -m "codex(init): seed via ${OPENAI_MODEL}"
          git push -u origin "${BRANCH_NAME}"

      - uses: actions/upload-artifact@v4
        if: always()
        with:
          name: ai-debug
          path: |
            ai/prompt.md
            ai/request.json
            ai/response.json
            ai/out.files.json