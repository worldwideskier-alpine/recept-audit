name: "Codex (sliced)"
on:
  workflow_dispatch:
    inputs:
      tasks_glob:
        description: "Task file patterns (space-separated pathspecs, e.g. 'spec/tasks/*.yml spec/custom/**/*.yml')"
        required: false
        default: "spec/tasks/*.yml"

permissions:
  contents: read

concurrency:
  group: "codex-sliced"
  cancel-in-progress: true

jobs:
  # 追加: タスクリストを自動収集して matrix を生成
  discover:
    name: "discover tasks"
    runs-on: ubuntu-24.04
    outputs:
      matrix: ${{ steps.build.outputs.matrix }}
    steps:
      - name: "checkout"
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
          persist-credentials: false
          lfs: false
          submodules: false
          sparse-checkout-cone-mode: true
          set-safe-directory: true

      - name: "build dynamic matrix from tasks_glob"
        id: build
        shell: bash
        run: |
          set -euo pipefail
          PATTERNS="${{ github.event.inputs.tasks_glob }}"
          # Git の pathspec(** 含む)でマッチ。存在しなくてもエラーにしないために || true
          git ls-files -z -- $PATTERNS > files.z || true
          if [ ! -s files.z ]; then
            echo "::error::No task files matched pattern(s): $PATTERNS"
            exit 1
          fi
          tr '\0' '\n' < files.z | sed '/^$/d' | sort -u > files.txt
          echo "Resolved tasks:"
          cat files.txt
          MATRIX_JSON="$(jq -cRs '{task: (split("\n") | map(select(length>0)))}' < files.txt)"
          echo "matrix=${MATRIX_JSON}" >> "$GITHUB_OUTPUT"

  codex:
    name: "codex (sliced)"
    runs-on: ubuntu-24.04
    needs: discover

    strategy:
      fail-fast: false
      max-parallel: 2
      matrix: ${{ fromJSON(needs.discover.outputs.matrix) }}

    env:
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      OPENAI_MODEL: "gpt-5-codex"
      OPENAI_BASE_URL: ${{ secrets.OPENAI_BASE_URL }}
      ENDPOINT: "https://api.openai.com/v1/responses"

      SPEC_ROOT: "spec"
      PROMPT_FILE: "ai/prompt.md"
      REQUEST_JSON: "ai/request.json"
      RESPONSE_JSON: "ai/response.json"
      OUT_JSON: "ai/out.files.json"
      STAGING_DIR: "codex_out"

      CURL_TIMEOUT: 900
      CURL_RETRIES: 2
      CURL_RETRY_DELAY: 15
      TITLE: "Codex generation prompt"
      MAX_TOKENS: "24576"          # ← 対処1: 出力量を増やす
      REASONING_EFFORT: "low"      # ← 対処2: 推論トークン抑制
      # TEMPERATURE 行は削除（非対応）

    steps:
      - name: "checkout"
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
          persist-credentials: false
          lfs: false
          submodules: false
          sparse-checkout-cone-mode: true
          set-safe-directory: true

      - name: "install jq/yq/coreutils/python3"
        run: |
          set -euo pipefail
          sudo apt-get update -y
          # yq は必須（assemble で使用）
          sudo apt-get install -y jq yq coreutils python3
          yq --version

      - name: "prepare task vars"
        id: task
        run: |
          set -euo pipefail
          TASK_FILE="${{ matrix.task }}"
          echo "task_file=${TASK_FILE}" >> "$GITHUB_OUTPUT"

      # スロットごとに固有名でアップロード（replace関数は使わずシェルで安全名化）
      - name: "compute artifact name (per slot)"
        id: art
        run: |
          set -euo pipefail
          task="${{ steps.task.outputs.task_file }}"
          safe="${task//\//_}"
          safe="${safe//./_}"
          echo "name=codex_out_${safe}" >> "$GITHUB_OUTPUT"

      - name: "assemble prompt.md (includes only)"
        run: |
          set -euo pipefail
          mkdir -p "ai"
          : > "$PROMPT_FILE"
          TASK_FILE="${{ steps.task.outputs.task_file }}"

          TITLE_VAL="$TITLE"
          if [ -f "$TASK_FILE" ]; then
            T="$(yq -r '.title // ""' "$TASK_FILE" 2>/dev/null || true)"
            if [ -n "${T:-}" ]; then TITLE_VAL="$T"; fi
          fi

          printf "# %s\n\n" "$TITLE_VAL" >> "$PROMPT_FILE"
          printf "## STRICT RULES\n\n" >> "$PROMPT_FILE"
          printf -- "- Return ONLY JSON (no prose) that matches {\\\"files\\\":[{\\\"path\\\":string,\\\"content\\\":string},...]}.\n" >> "$PROMPT_FILE"
          printf -- "- Implement runnable APPLICATION CODE and TESTS.\n" >> "$PROMPT_FILE"
          printf -- "- Emit at least one code file under \\\"/src\\\" or \\\"/app\\\".\n" >> "$PROMPT_FILE"
          printf -- "- NEVER write under the \\\"ai/\\\" directory.\n" >> "$PROMPT_FILE"
          # 追加: 分割出力ポリシー（モデル側の約束事）
          printf -- "- Output at MOST 20 files per response. If more files remain, set has_more=true and provide next_cursor; do NOT repeat previously emitted files.\n" >> "$PROMPT_FILE"
          printf -- "- When continuing, you will receive a line like 'CONTINUE_FROM_CURSOR: <cursor>'. Resume deterministically (order by path asc) and stop when done with has_more=false.\n" >> "$PROMPT_FILE"
          printf -- "- Always include next_cursor; set \\\"\\\" when has_more=false.\n\n" >> "$PROMPT_FILE"

          printf "## SPEC CONTENT\n" >> "$PROMPT_FILE"

          # includes only
          if yq -e '.include' "$TASK_FILE" >/dev/null 2>&1; then
            yq -r '.include[]' "$TASK_FILE" | while read -r f; do
              [ -f "$SPEC_ROOT/$f" ] || continue
              printf "\n### %s\n\n" "$f" >> "$PROMPT_FILE"
              sed -e 's/\r$//' "$SPEC_ROOT/$f" | head -n 4000 >> "$PROMPT_FILE"
            done
          fi

      - name: "build ai/request.json"
        run: |
          set -euo pipefail
          ENDPOINT="${ENDPOINT:-${OPENAI_BASE_URL:-https://api.openai.com}/v1/responses}"
          jq -n \
            --arg model "$OPENAI_MODEL" \
            --rawfile prompt "$PROMPT_FILE" \
            --argjson max_out "${MAX_TOKENS:-24576}" \
            --arg effort "${REASONING_EFFORT:-low}" '
          {
            model: $model,
            reasoning: { effort: $effort },
            text: {
              format: {
                type: "json_schema",
                name: "emit_files",
                strict: true,
                schema: {
                  type: "object",
                  additionalProperties: false,
                  required: ["files","has_more","next_cursor"],
                  properties: {
                    files: {
                      type: "array",
                      minItems: 0,
                      maxItems: 20,
                      items: {
                        type: "object",
                        additionalProperties: false,
                        required: ["path","content"],
                        properties: {
                          path:    { type: "string", minLength: 1 },
                          content: { type: "string" }
                        }
                      }
                    },
                    has_more:    { type: "boolean" },
                    next_cursor: { type: "string", minLength: 0 }
                  }
                }
              }
            },
            input: [
              { role: "system", content: [ { type: "input_text", text: "You are Codex. Output ONLY a JSON object with the exact shape {\\\\\\\"files\\\\\\\":[{\\\\\\\"path\\\\\\\":string,\\\\\\\"content\\\\\\\":string},...],\\\\\\\"has_more\\\\\\\":boolean,\\\\\\\"next_cursor\\\\\\\":string}. No prose, no code fences. Write full, runnable code. No placeholders. Never write inside ai/. Emit at most 20 files per response; if more remain, set has_more=true and provide next_cursor. Always include next_cursor; set \\\"\\\" when has_more=false. Never repeat previously emitted files." } ] },
              { role: "user",   content: [ { type: "input_text", text: ("Implement the SPEC as runnable application code and tests. Return files to write as JSON only.\\n\\n" + $prompt) } ] }
            ],
            max_output_tokens: $max_out
          }' > "$REQUEST_JSON"

      - name: "call OpenAI Responses API (with output chunking)"
        run: |
          set -euo pipefail
          ENDPOINT="${ENDPOINT:-${OPENAI_BASE_URL:-https://api.openai.com}/v1/responses}"

          # 初回リクエスト実行（既存の堅牢な処理を温存）
          http_code="$(
            curl --fail-with-body -sS \
              --connect-timeout 30 \
              --max-time "${CURL_TIMEOUT}" \
              --retry "${CURL_RETRIES}" \
              --retry-all-errors \
              --retry-delay "${CURL_RETRY_DELAY}" \
              -H "Authorization: Bearer ${OPENAI_API_KEY}" \
              -H "Content-Type: application/json" \
              -d @"$REQUEST_JSON" "$ENDPOINT" \
              -w "%{http_code}" -o "$RESPONSE_JSON" || true
          )"
          http_code="$(echo -n "$http_code" | tr -d '\r\n[:space:]')"
          echo "HTTP_STATUS=${http_code}"

          if [ "$http_code" = "500" ] || [ "$http_code" = "502" ] || [ "$http_code" = "503" ] || [ "$http_code" = "504" ]; then
            echo "::group::response.json (first 120 lines)"; head -n 120 "$RESPONSE_JSON" || true; echo "::endgroup::"
            echo "::notice title=fallback::HTTP ${http_code} detected. Retrying once with max_output_tokens=12288"
            jq '. + {max_output_tokens: 12288}' "$REQUEST_JSON" > ai/request.fallback.json
            http_code_fallback="$(
              curl --fail-with-body -sS \
                --connect-timeout 30 \
                --max-time "${CURL_TIMEOUT}" \
                --retry 0 \
                -H "Authorization: Bearer ${OPENAI_API_KEY}" \
                -H "Content-Type: application/json" \
                -d @ai/request.fallback.json "$ENDPOINT" \
                -w "%{http_code}" -o "$RESPONSE_JSON" || true
            )"
            http_code_fallback="$(echo -n "$http_code_fallback" | tr -d '\r\n[:space:]')"
            echo "HTTP_STATUS_FALLBACK=${http_code_fallback}"
            http_code="${http_code_fallback}"
          fi

          if [ "${http_code}" -lt 200 ] || [ "${http_code}" -ge 400 ]; then
            echo "::error title=OpenAI API returned ${http_code}::See response.json for details"
            echo "::group::response.json (first 120 lines)"; head -n 120 "$RESPONSE_JSON" || true; echo "::endgroup::"
            exit 22
          fi

          echo "::group::response.json (first 80 lines)"; head -n 80 "$RESPONSE_JSON" || true; echo "::endgroup::"

          STATUS="$(jq -r '.status // empty' "$RESPONSE_JSON")"
          REASON="$(jq -r '.incomplete_details.reason // empty' "$RESPONSE_JSON")"

          # 既存の max_output_tokens 対応（温存）
          if [ "${STATUS}" != "completed" ] && [ "${REASON}" = "max_output_tokens" ]; then
            echo "::notice title=fallback::incomplete(max_output_tokens). Retrying with higher budget & low reasoning"
            jq '. + {max_output_tokens: 32768, reasoning:{effort:"low"}}' \
              "$REQUEST_JSON" > ai/request.bump.json
            http_code_bump="$(
              curl --fail-with-body -sS \
                --connect-timeout 30 \
                --max-time "${CURL_TIMEOUT}" \
                --retry 0 \
                -H "Authorization: Bearer ${OPENAI_API_KEY}" \
                -H "Content-Type: application/json" \
                -d @ai/request.bump.json "$ENDPOINT" \
                -w "%{http_code}" -o "$RESPONSE_JSON" || true
            )"
            http_code_bump="$(echo -n "$http_code_bump" | tr -d '\r\n[:space:]')"
            echo "HTTP_STATUS_BUMP=${http_code_bump}"
          fi

          STATUS="$(jq -r '.status // empty' "$RESPONSE_JSON")"
          if [ "${STATUS}" != "completed" ]; then
            REASON="$(jq -r '.incomplete_details.reason // "unknown"' "$RESPONSE_JSON")"
            echo "::error title=OpenAI response incomplete::status=${STATUS}, reason=${REASON}"
            echo "::group::response.json (first 200 lines)"; head -n 200 "$RESPONSE_JSON" || true; echo "::endgroup::"
            exit 22
          fi

          # ここから「分割出力」の集約処理
          echo '{"files":[]}' > "$OUT_JSON"

          extract_chunk () {
            # 出力テキスト(JSON文字列)を取り出して検証
            jq -e -r '
              .output_text
              // ( [ .output[]? .content[]? | select(.type=="output_text") | .text ] | .[0] )
              // ( [ .output[]? .content[]? | select(.type=="text")        | .text ] | .[0] )
            ' "$RESPONSE_JSON" > ai/chunk.raw.txt
            jq -e . ai/chunk.raw.txt > ai/chunk.json

            # files を累積
            jq -s '{files: (.[0].files + .[1].files)}' "$OUT_JSON" ai/chunk.json > ai/.merge.json
            mv ai/.merge.json "$OUT_JSON"

            # has_more / next_cursor を返す
            HAS_MORE="$(jq -r '(.has_more // false) | tostring' ai/chunk.json)"
            CURSOR="$(jq -r '.next_cursor // empty' ai/chunk.json)"
            echo "$HAS_MORE" > ai/.has_more
            echo "$CURSOR"   > ai/.cursor
          }

          extract_chunk

          # 追加ページを取得（最大30ループの安全弁）
          LIMIT=30
          n=0
          while [ "$(cat ai/.has_more)" = "true" ] && [ $n -lt $LIMIT ]; do
            n=$((n+1))
            cursor="$(cat ai/.cursor)"

            # 続き要求（元の request.json に追記するだけで既存仕様を温存）
            jq --arg cursor "$cursor" '
              .input += [ { role:"user", content:[{ type:"input_text", text: ("CONTINUE_FROM_CURSOR: " + $cursor) }] } ]
            ' "$REQUEST_JSON" > ai/request.cont.json

            http_code_cont="$(
              curl --fail-with-body -sS \
                --connect-timeout 30 \
                --max-time "${CURL_TIMEOUT}" \
                --retry "${CURL_RETRIES}" \
                --retry-all-errors \
                --retry-delay "${CURL_RETRY_DELAY}" \
                -H "Authorization: Bearer ${OPENAI_API_KEY}" \
                -H "Content-Type: application/json" \
                -d @ai/request.cont.json "$ENDPOINT" \
                -w "%{http_code}" -o "$RESPONSE_JSON" || true
            )"
            http_code_cont="$(echo -n "$http_code_cont" | tr -d '\r\n[:space:]')"
            echo "HTTP_STATUS_CONT=${http_code_cont}"

            if [ "${http_code_cont}" -lt 200 ] || [ "${http_code_cont}" -ge 400 ]; then
              echo "::error title=OpenAI API returned ${http_code_cont} (continuation)::See response.json for details"
              echo "::group::response.json (first 120 lines)"; head -n 120 "$RESPONSE_JSON" || true; echo "::endgroup::"
              exit 22
            fi

            STATUS_CONT="$(jq -r '.status // empty' "$RESPONSE_JSON")"
            if [ "${STATUS_CONT}" != "completed" ]; then
              REASON_CONT="$(jq -r '.incomplete_details.reason // "unknown"' "$RESPONSE_JSON")"
              echo "::error title=OpenAI response incomplete (continuation)::status=${STATUS_CONT}, reason=${REASON_CONT}"
              echo "::group::response.json (first 200 lines)"; head -n 200 "$RESPONSE_JSON" || true; echo "::endgroup::"
              exit 22
            fi

            extract_chunk
          done

          # 重複 path は最後のものを採用
          jq '
            .files
            | group_by(.path)
            | map(.[-1])
            | {files: .}
          ' "$OUT_JSON" > ai/.dedup.json && mv ai/.dedup.json "$OUT_JSON"

          # 最終チェック
          jq -e 'type=="object" and has("files") and (.files|type=="array")' "$OUT_JSON" >/dev/null
          if [ "$(jq '.files | length' "$OUT_JSON")" -eq 0 ]; then
            echo "::error title=no files emitted after pagination::Model returned zero writable files"
            exit 1
          fi

      - name: "extract model JSON and write files"
        run: |
          set -euo pipefail
          mkdir -p "$STAGING_DIR"

          # すでに集約済み OUT_JSON があればそれを優先（分割出力対応）
          if jq -e 'type=="object" and has("files") and (.files|type=="array") and (.files|length>=0)' "$OUT_JSON" >/dev/null 2>&1; then
            echo "Using aggregated OUT_JSON (paginated)."
          else
            # 従来の単発パース（後方互換）
            jq -e -r '
              .output_text
              // ( [ .output[]? .content[]? | select(.type=="output_text") | .text ] | .[0] )
              // ( [ .output[]? .content[]? | select(.type=="text")        | .text ] | .[0] )
            ' "$RESPONSE_JSON" > ai/out.raw.txt
            jq -e . ai/out.raw.txt > "$OUT_JSON"
            jq -e 'type=="object" and has("files") and (.files|type=="array") and (.files|length>0)' "$OUT_JSON" >/devnull
          fi

          i=0
          while IFS= read -r row; do
            path=$(printf '%s' "$row" | jq -r '.path')
            content=$(printf '%s' "$row" | jq -r '.content')
            case "$path" in
              ai/*|./ai/*) echo "::warning title=skipped forbidden path::$path"; continue;;
            esac
            mkdir -p "$(dirname "$path")" "$(dirname "$STAGING_DIR/$path")"
            printf '%s' "$content" > "$path"
            printf '%s' "$content" > "$STAGING_DIR/$path"
            echo "wrote $path"; i=$((i+1))
          done < <(jq -c '.files[]' "$OUT_JSON")
          if [ "$i" -eq 0 ]; then
            echo "::error title=no files written::Model returned zero writable files"
            exit 1
          fi

      - name: "upload artifact (codex_out)"
        uses: actions/upload-artifact@v4
        with:
          name: "${{ steps.art.outputs.name }}"
          path: "${{ env.STAGING_DIR }}"
          if-no-files-found: "error"
