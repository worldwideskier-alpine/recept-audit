name: "Codex Generate (spec-driven reusable)"

on:
  workflow_call:
    inputs:
      mode:
        description: "実行モード: full(全生成) / incremental(差分)"
        required: false
        default: "full"
        type: string
      model:
        description: "OpenAI モデル名 (任意)"
        required: false
        default: ""
        type: string
    secrets:
      OPENAI_API_KEY:
        description: "OpenAI API key"
        required: true

  workflow_dispatch:
    inputs:
      mode:
        description: "実行モード: full(全生成) / incremental(差分)"
        required: false
        default: "full"
        type: choice
        options: ["full", "incremental"]
      model:
        description: "OpenAI モデル名 (任意)"
        required: false
        default: ""
        type: string

permissions:
  contents: write
  pull-requests: write

jobs:
  generate:
    name: "Generate from specs"
    runs-on: "ubuntu-latest"

    env:
      # 仕様のルート/サブディレクトリ
      SPEC_ROOT: "spec"
      SPEC_DIRS: "foundation env-profiles features tests"
      # 生成物/媒介ファイル
      PROMPT_FILE: "ai/prompt.md"
      PATCH_FILE: "ai/patch.diff"
      # モデル
      MODEL_DEFAULT: "gpt-4o-mini"
      OPENAI_MODEL: "${{ inputs.model }}"
      MODE: "${{ inputs.mode }}"
      # 全ステップで参照可能に
      OPENAI_API_KEY: "${{ secrets.OPENAI_API_KEY }}"

    steps:
      - name: "Checkout"
        uses: "actions/checkout@v4"

      - name: "Setup Node (cache if lock exists)"
        if: ${{ hashFiles('**/package-lock.json', '**/npm-shrinkwrap.json', '**/yarn.lock') != '' }}
        uses: "actions/setup-node@v4"
        with:
          node-version: "20"
          cache: "npm"

      - name: "Setup Node (no cache)"
        if: ${{ hashFiles('**/package-lock.json', '**/npm-shrinkwrap.json', '**/yarn.lock') == '' }}
        uses: "actions/setup-node@v4"
        with:
          node-version: "20"

      - name: "Preflight: API key"
        shell: "bash"
        run: |
          set -euo pipefail
          if [ -z "${OPENAI_API_KEY:-}" ]; then
            echo "::error::OPENAI_API_KEY is not set"
            exit 1
          fi
          mkdir -p "ai" "tools"

      - name: "Compose prompt from spec (no-heredoc)"
        shell: "bash"
        run: |
          set -euo pipefail
          : > "$PROMPT_FILE"
          printf "%s\n" "# Codex generation prompt" >> "$PROMPT_FILE"
          printf "%s\n" "" >> "$PROMPT_FILE"
          printf "%s\n" "## Mode: ${MODE}" >> "$PROMPT_FILE"
          printf "%s\n" "" >> "$PROMPT_FILE"

          tmp_list="$(mktemp)"
          for d in $SPEC_DIRS; do
            if [ -d "${SPEC_ROOT}/${d}" ]; then
              find "${SPEC_ROOT}/${d}" -type f \
                \( -name "*.md" -o -name "*.txt" -o -name "*.yaml" -o -name "*.yml" -o -name "*.json" \) \
                >> "$tmp_list"
            fi
          done

          if [ -s "$tmp_list" ]; then
            LC_ALL=C sort "$tmp_list" -o "$tmp_list"
            while IFS= read -r f; do
              printf "%s\n" "" >> "$PROMPT_FILE"
              printf "%s\n" "### $(basename "$f")" >> "$PROMPT_FILE"
              printf "%s\n" "" >> "$PROMPT_FILE"
              sed -e 's/\r$//' "$f" >> "$PROMPT_FILE"
              printf "%s\n" "" >> "$PROMPT_FILE"
            done < "$tmp_list"
          fi
          rm -f "$tmp_list"

          # ---- OUTPUT CONTRACT (MUST) ----
          printf "%s\n" "" >> "$PROMPT_FILE"
          printf "%s\n" "## OUTPUT CONTRACT (MUST)" >> "$PROMPT_FILE"
          printf "%s\n" "" >> "$PROMPT_FILE"
          printf "%s\n" "- Return a single Unified Diff patch rooted at the repository." >> "$PROMPT_FILE"
          printf "%s\n" "- No prose, no explanations, no code fences, no headings." >> "$PROMPT_FILE"
          printf "%s\n" "- Start with either 'diff --git' lines or with '--- a/' then '+++ b/'." >> "$PROMPT_FILE"
          printf "%s\n" "- If truly no changes are required, emit a minimal no-op patch touching 'ai/.noop':" >> "$PROMPT_FILE"
          printf "%s\n" "" >> "$PROMPT_FILE"
          printf "%s\n" "--- a/ai/.noop" >> "$PROMPT_FILE"
          printf "%s\n" "+++ b/ai/.noop" >> "$PROMPT_FILE"
          printf "%s\n" "@@ -1 +1 @@" >> "$PROMPT_FILE"
          printf "%s\n" "-placeholder" >> "$PROMPT_FILE"
          printf "%s\n" "+placeholder" >> "$PROMPT_FILE"

      - name: "Create tools/run_codex.js (no heredoc)"
        shell: "bash"
        run: |
          set -euo pipefail
          mkdir -p tools ai
          rm -f tools/run_codex.js
          printf "%s\n" "'use strict';" >> tools/run_codex.js
          printf "%s\n" "const fs = require('fs');" >> tools/run_codex.js
          printf "%s\n" "const path = require('path');" >> tools/run_codex.js
          printf "%s\n" "const https = require('https');" >> tools/run_codex.js
          printf "%s\n" "const PROMPT_FILE = process.env.PROMPT_FILE || 'ai/prompt.md';" >> tools/run_codex.js
          printf "%s\n" "const PATCH_FILE  = process.env.PATCH_FILE  || 'ai/patch.diff';" >> tools/run_codex.js
          printf "%s\n" "const MODEL = (process.env.OPENAI_MODEL && process.env.OPENAI_MODEL.length>0) ? process.env.OPENAI_MODEL : (process.env.MODEL_DEFAULT||'gpt-4o-mini');" >> tools/run_codex.js
          printf "%s\n" "const KEY = process.env.OPENAI_API_KEY;" >> tools/run_codex.js
          printf "%s\n" "function extractText(j){" >> tools/run_codex.js
          printf "%s\n" "  if (!j) return '';" >> tools/run_codex.js
          printf "%s\n" "  if (typeof j.output_text === 'string') return j.output_text;" >> tools/run_codex.js
          printf "%s\n" "  if (Array.isArray(j.output_text)) return j.output_text.join('');" >> tools/run_codex.js
          printf "%s\n" "  if (typeof j.output === 'string') return j.output;" >> tools/run_codex.js
          printf "%s\n" "  if (Array.isArray(j.output)) return j.output.map(x => (typeof x==='string'?x:(x?.text||x?.content||''))).join('');" >> tools/run_codex.js
          printf "%s\n" "  if (j.choices && j.choices.length){" >> tools/run_codex.js
          printf "%s\n" "    const c0=j.choices[0];" >> tools/run_codex.js
          printf "%s\n" "    if (c0?.message?.content){ if (Array.isArray(c0.message.content)) return c0.message.content.map(c=>c.text||c.string||'').join(''); return c0.message.content; }" >> tools/run_codex.js
          printf "%s\n" "    if (typeof c0?.text==='string') return c0.text;" >> tools/run_codex.js
          printf "%s\n" "  }" >> tools/run_codex.js
          printf "%s\n" "  if (typeof j.data==='string') return j.data;" >> tools/run_codex.js
          printf "%s\n" "  return '';" >> tools/run_codex.js
          printf "%s\n" "}" >> tools/run_codex.js
          printf "%s\n" "if (!KEY) { console.error('OPENAI_API_KEY missing'); process.exit(2); }" >> tools/run_codex.js
          printf "%s\n" "const prompt = fs.readFileSync(PROMPT_FILE, 'utf8');" >> tools/run_codex.js
          printf "%s\n" "const body = JSON.stringify({ model: MODEL, temperature: 0.1, response_format: { type: 'text' }, input: [{ role: 'user', content: prompt + '\\n\\n[MUST OUTPUT] Return only a unified diff patch (UTF-8), repository root. No prose. No code fences.' }] });" >> tools/run_codex.js
          printf "%s\n" "const req = https.request({ hostname: 'api.openai.com', path: '/v1/responses', method: 'POST', headers: { 'Content-Type': 'application/json', 'Authorization': 'Bearer '+KEY } }, (res)=>{" >> tools/run_codex.js
          printf "%s\n" "  let data=''; res.on('data',c=>data+=c); res.on('end',()=>{" >> tools/run_codex.js
          printf "%s\n" "    if (res.statusCode>=300){ console.error('OpenAI
