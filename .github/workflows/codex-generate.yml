# .github/workflows/codex-generate.yml
name: "Codex Generate (spec-driven reusable)"

on:
  workflow_call:
    inputs:
      mode:
        description: "実行モード: full(全生成) / incremental(差分)"
        required: false
        default: "full"
        type: string
      model:
        description: "OpenAI モデル名 (例: gpt-5-codex / gpt-5 / gpt-4.1 / gpt-4o-mini)"
        required: false
        default: ""
        type: string
    secrets:
      OPENAI_API_KEY:
        description: "OpenAI API key"
        required: true

  workflow_dispatch:
    inputs:
      mode:
        description: "実行モード: full(全生成) / incremental(差分)"
        required: false
        default: "full"
        type: choice
        options: ["full", "incremental"]
      model:
        description: "OpenAI モデル名 (例: gpt-5-codex / gpt-5 / gpt-4.1 / gpt-4o-mini)"
        required: false
        default: ""
        type: string

permissions:
  contents: write
  pull-requests: write

jobs:
  generate:
    name: "Generate from specs"
    runs-on: ubuntu-latest

    env:
      # 仕様のルート/サブディレクトリ
      SPEC_ROOT: spec
      SPEC_DIRS: "foundation env-profiles features tests"
      # 生成物/媒介ファイル
      PROMPT_FILE: ai/prompt.md
      PATCH_FILE: ai/patch.diff
      # 既定モデル（未指定時に使用）
      MODEL_DEFAULT: gpt-4o-mini
      OPENAI_MODEL: ${{ inputs.model }}
      MODE: ${{ inputs.mode }}
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      # 企業プロキシなどを使う場合のみ設定（未設定なら公式 API）
      OPENAI_BASE_URL: ${{ vars.OPENAI_BASE_URL }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node (cache if lock exists)
        if: ${{ hashFiles('**/package-lock.json', '**/npm-shrinkwrap.json', '**/yarn.lock') != '' }}
        uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: npm

      - name: Setup Node (no cache)
        if: ${{ hashFiles('**/package-lock.json', '**/npm-shrinkwrap.json', '**/yarn.lock') == '' }}
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Preflight: API key
        shell: bash
        run: |
          set -euo pipefail
          if [ -z "${OPENAI_API_KEY:-}" ]; then
            echo "::error::OPENAI_API_KEY is not set"
            exit 1
          fi
          mkdir -p ai

      - name: Compose prompt from spec (no-heredoc)
        shell: bash
        run: |
          set -euo pipefail
          : > "$PROMPT_FILE"
          printf "%s\n" "# Codex generation prompt" >> "$PROMPT_FILE"
          printf "%s\n" "" >> "$PROMPT_FILE"
          printf "%s\n" "## Mode: ${MODE}" >> "$PROMPT_FILE"
          printf "%s\n" "" >> "$PROMPT_FILE"

          tmp_list="$(mktemp)"
          for d in $SPEC_DIRS; do
            if [ -d "${SPEC_ROOT}/${d}" ]; then
              find "${SPEC_ROOT}/${d}" -type f \
                \( -name "*.md" -o -name "*.txt" -o -name "*.yaml" -o -name "*.yml" -o -name "*.json" \) \
                >> "$tmp_list"
            fi
          done

          if [ -s "$tmp_list" ]; then
            LC_ALL=C sort "$tmp_list" -o "$tmp_list"
            while IFS= read -r f; do
              printf "%s\n" "" >> "$PROMPT_FILE"
              printf "%s\n" "### $(basename "$f")" >> "$PROMPT_FILE"
              printf "%s\n" "" >> "$PROMPT_FILE"
              sed -e 's/\r$//' "$f" >> "$PROMPT_FILE"
              printf "%s\n" "" >> "$PROMPT_FILE"
            done < "$tmp_list"
          fi
          rm -f "$tmp_list"

          {
            printf "\n## OUTPUT CONTRACT (MUST)\n\n"
            printf -- "- Return a single Unified Diff patch rooted at the repository.\n"
            printf -- "- No prose, no explanations, no code fences, no headings.\n"
            printf -- "- Start with either 'diff --git' lines or with '--- a/' then '+++ b/'.\n"
            printf -- "- If truly no changes are required, emit a minimal no-op patch touching 'ai/.noop':\n\n"
            printf -- "--- a/ai/.noop\n"
            printf -- "+++ b/ai/.noop\n"
            printf -- "@@ -1 +1 @@\n"
            printf -- "-placeholder\n"
            printf -- "+placeholder\n"
          } >> "$PROMPT_FILE"

      - name: Call OpenAI (curl + jq, no heredoc)
        shell: bash
        run: |
          set -euo pipefail
          BASE="${OPENAI_BASE_URL:-https://api.openai.com}"

          # ---- モデル名のサニタイズ ----
          _in="${OPENAI_MODEL:-}"
          MODEL="$MODEL_DEFAULT"
          if [ -n "$_in" ]; then
            case "$_in" in
              gpt-*|o* ) MODEL="$_in" ;;  # 代表的な命名のみ許可
              * ) echo "note: unknown model '$_in' -> fallback to $MODEL_DEFAULT" ;;
            esac
          fi
          echo "Using model: $MODEL"
          echo "Base URL  : $BASE"

          # ---- エンドポイント自動選択 ----
          # gpt-5-pro / gpt-5-codex など Responses 専用・推奨モデルは /v1/responses に送る
          API="chat"
          case "$MODEL" in
            *codex*|*Codex*|gpt-5-pro) API="responses" ;;
          esac
