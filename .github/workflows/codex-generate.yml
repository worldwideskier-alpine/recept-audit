name: "Codex Generate (spec-driven reusable)"

on:
  workflow_call:
    inputs:
      mode:
        description: "実行モード: full(全生成) / incremental(差分)"
        required: false
        default: "full"
        type: string
      model:
        description: "OpenAI モデル名 (例: gpt-5-codex / gpt-5 / gpt-4.1 / gpt-4o-mini)"
        required: false
        default: ""
        type: string
    secrets:
      OPENAI_API_KEY:
        description: "OpenAI API key"
        required: true

  workflow_dispatch:
    inputs:
      mode:
        description: "実行モード: full(全生成) / incremental(差分)"
        required: false
        default: "full"
        type: choice
        options: ["full", "incremental"]
      model:
        description: "OpenAI モデル名 (例: gpt-5-codex / gpt-5 / gpt-4.1 / gpt-4o-mini)"
        required: false
        default: ""
        type: string

permissions:
  contents: write
  pull-requests: write

jobs:
  generate:
    name: "Generate from specs"
    runs-on: "ubuntu-latest"

    env:
      SPEC_ROOT: "spec"
      SPEC_DIRS: "foundation env-profiles features tests"
      PROMPT_FILE: "ai/prompt.md"
      PATCH_FILE: "ai/patch.diff"
      MODEL_DEFAULT: "gpt-4o-mini"
      OPENAI_MODEL: "${{ inputs.model }}"
      MODE: "${{ inputs.mode }}"
      OPENAI_API_KEY: "${{ secrets.OPENAI_API_KEY }}"
      OPENAI_BASE_URL: "${{ vars.OPENAI_BASE_URL }}"

    steps:
      - name: "Checkout"
        uses: actions/checkout@v4

      - name: "Setup Node (cache if lock exists)"
        if: ${{ hashFiles('**/package-lock.json', '**/npm-shrinkwrap.json', '**/yarn.lock') != '' }}
        uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: "npm"

      - name: "Setup Node (no cache)"
        if: ${{ hashFiles('**/package-lock.json', '**/npm-shrinkwrap.json', '**/yarn.lock') == '' }}
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: "Preflight: API key"
        shell: bash
        run: |
          set -euo pipefail
          if [ -z "${OPENAI_API_KEY:-}" ]; then
            echo "::error::OPENAI_API_KEY is not set"
            exit 1
          fi
          mkdir -p ai

      - name: "Compose prompt from spec (no-heredoc)"
        shell: bash
        run: |
          set -euo pipefail
          : > "$PROMPT_FILE"
          printf "%s\n" "# Codex generation prompt" >> "$PROMPT_FILE"
          printf "%s\n" "" >> "$PROMPT_FILE"
          printf "%s\n" "## Mode: ${MODE}" >> "$PROMPT_FILE"
          printf "%s\n" "" >> "$PROMPT_FILE"

          tmp_list="$(mktemp)"
          for d in $SPEC_DIRS; do
            if [ -d "${SPEC_ROOT}/${d}" ]; then
              find "${SPEC_ROOT}/${d}" -type f \
                \( -name "*.md" -o -name "*.txt" -o -name "*.yaml" -o -name "*.yml" -o -name "*.json" \) \
                >> "$tmp_list"
            fi
          done

          if [ -s "$tmp_list" ]; then
            LC_ALL=C sort "$tmp_list" -o "$tmp_list"
            while IFS= read -r f; do
              printf "%s\n" "" >> "$PROMPT_FILE"
              printf "%s\n" "### $(basename "$f")" >> "$PROMPT_FILE"
              printf "%s\n" "" >> "$PROMPT_FILE"
              sed -e 's/\r$//' "$f" >> "$PROMPT_FILE"
              printf "%s\n" "" >> "$PROMPT_FILE"
            done < "$tmp_list"
          fi
          rm -f "$tmp_list"

          {
            printf "\n## OUTPUT CONTRACT (MUST)\n\n"
            printf -- "- Return a single Unified Diff patch rooted at the repository.\n"
            printf -- "- No prose, no explanations, no code fences, no headings.\n"
            printf -- "- Start with either 'diff --git' lines or with '--- a/' then '+++ b/'.\n"
            printf -- "- If truly no changes are required, emit a minimal no-op patch touching 'ai/.noop':\n\n"
            printf -- "--- a/ai/.noop\n"
            printf -- "+++ b/ai/.noop\n"
            printf -- "@@ -1 +1 @@\n"
            printf -- "-placeholder\n"
            printf -- "+placeholder\n"
          } >> "$PROMPT_FILE"

      - name: "Call OpenAI (curl + jq, no heredoc) — auto route"
        shell: bash
        run: |
          set -euo pipefail

          # --- model sanitize ---
          _in="${OPENAI_MODEL:-}"
          MODEL="$MODEL_DEFAULT"
          if [ -n "$_in" ]; then
            case "$_in" in
              gpt-*|o* ) MODEL="$_in" ;;
              * ) echo "note: unknown model '$_in' -> fallback to $MODEL_DEFAULT" ;;
            esac
          fi
          BASE="${OPENAI_BASE_URL:-https://api.openai.com}"
          echo "Using model: $MODEL"
          echo "Base URL  : $BASE"

          # --- route switch ---
          if printf "%s" "$MODEL" | grep -qiE '^gpt-5-codex( |$|-|:)'; then
            # ===== Responses API (gpt-5-codex) =====
            jq -n \
              --arg model "$MODEL" \
              --rawfile prompt "$PROMPT_FILE" \
              '{
                model: $model,
                max_output_tokens: 4096,
                response_format: { type: "text" },
                input: [
                  {
                    role: "user",
                    content: [
                      { type: "input_text",
                        text: ($prompt + "\n\n[MUST OUTPUT] Return only a unified diff patch (UTF-8), repository root. No prose. No code fences.") }
                    ]
                  }
                ]
              }' > ai/request.json

            ENDPOINT="${BASE%/}/v1/responses"
          else
            # ===== Chat Completions (その他モデル) =====
            jq -n \
              --arg model "$MODEL" \
              --rawfile prompt "$PROMPT_FILE" \
              '{
                model: $model,
                temperature: 0.1,
                max_tokens: 4096,
                messages: [
                  {
                    role: "user",
                    content: ($prompt + "\n\n[MUST OUTPUT] Return only a unified diff patch (UTF-8), repository root. No prose. No code fences.")
                  }
                ]
              }' > ai/request.json

            ENDPOINT="${BASE%/}/v1/chat/completions"
          fi

          # --- call ---
          resp_with_code="$(mktemp)"
          curl -sS \
            -H "Authorization: Bearer ${OPENAI_API_KEY}" \
            -H "Content-Type: application/json" \
            -w "\n%{http_code}\n" \
            -d @ai/request.json \
            "$ENDPOINT" | tee "$resp_with_code" >/dev/null

          status="$(tail -n1 "$resp_with_code")"
          head -n -1 "$resp_with_code" > ai/response.json
          rm -f "$resp_with_code"

          if [ "${status}" -ge 300 ]; then
            echo "::error::OpenAI error ${status}"
            echo "---- request (trimmed) ----"; head -c 800 ai/request.json; echo
            echo "---- response body ----"; cat ai/response.json || true
            exit 3
          fi

          # --- extract text (Responses/Chat 両対応) ---
          jq -r '
            ( .output_text ) //
            ( ( .output // [] ) | select(type=="array")
                | map( if type=="string" then . else (.text // .content // "") end )
                | join("") ) //
            ( .choices[0].message.content // .choices[0].text // "" )
          ' ai/response.json > ai/out.txt

          # strip code fences if present
          sed -E -e '1{/^```[a-zA-Z-]*[[:space:]]*$/d;}' -e '${/^```[[:space:]]*$/d;}' -i ai/out.txt || true

          # drop any preamble lines before diff header
          awk 'f||/^(diff --git|--- a\/)/{f=1; print}' ai/out.txt > "$PATCH_FILE"

          # verify diff format
          if ! grep -Eq '^(diff --git|--- a/)' "$PATCH_FILE" || ! grep -Eq '(^\+\+\+ b/|^diff --git)' "$PATCH_FILE"; then
            echo "::error::model did not return a unified diff"
            exit 4
          fi
          echo "patch verified"

      - name: "Upload response debug (if any)"
        if: ${{ failure() }}
        uses: actions/upload-artifact@v4
        with:
          name: "ai-response-debug"
          path: |
            ai/request.json
            ai/response.json
            ai/out.txt
          if-no-files-found: ignore

      - name: "Upload prompt & patch (always)"
        if: ${{ always() }}
        uses: actions/upload-artifact@v4
        with:
          name: "ai-prompt-and-patch"
          path: |
            ai/prompt.md
            ai/patch.diff
          if-no-files-found: ignore
